{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoY3wR0wXGvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b1e823c1-96be-42e4-8258-50d48bea3c86"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgrZONHcsvla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "python "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA1qfI4aXl0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "import dataloader\n",
        "import net\n",
        "import numpy as np\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aibd2nC4YVmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "def train(config):\n",
        "\n",
        "\tdehaze_net = net.dehaze_net().cuda()\n",
        "\tdehaze_net.apply(weights_init)\n",
        "\n",
        "\ttrain_dataset = dataloader.dehazing_loader(config.orig_images_path,\n",
        "\t\t\t\t\t\t\t\t\t\t\t config.hazy_images_path)\t\t\n",
        "\tval_dataset = dataloader.dehazing_loader(config.orig_images_path,\n",
        "\t\t\t\t\t\t\t\t\t\t\t config.hazy_images_path, mode=\"val\")\t\t\n",
        "\ttrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True, num_workers=config.num_workers, pin_memory=True)\n",
        "\tval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=config.val_batch_size, shuffle=True, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "\tcriterion = nn.MSELoss().cuda()\n",
        "\toptimizer = torch.optim.Adam(dehaze_net.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "\t\n",
        "\tdehaze_net.train()\n",
        "\n",
        "\tfor epoch in range(config.num_epochs):\n",
        "\t\tfor iteration, (img_orig, img_haze) in enumerate(train_loader):\n",
        "\n",
        "\t\t\timg_orig = img_orig.cuda()\n",
        "\t\t\timg_haze = img_haze.cuda()\n",
        "\n",
        "\t\t\tclean_image = dehaze_net(img_haze)\n",
        "\n",
        "\t\t\tloss = criterion(clean_image, img_orig)\n",
        "\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tloss.backward()\n",
        "\t\t\ttorch.nn.utils.clip_grad_norm(dehaze_net.parameters(),config.grad_clip_norm)\n",
        "\t\t\toptimizer.step()\n",
        "\n",
        "\t\t\tif ((iteration+1) % config.display_iter) == 0:\n",
        "\t\t\t\tprint(\"Loss at iteration\", iteration+1, \":\", loss.item())\n",
        "\t\t\tif ((iteration+1) % config.snapshot_iter) == 0:\n",
        "\t\t\t\t\n",
        "\t\t\t\ttorch.save(dehaze_net.state_dict(), config.snapshots_folder + \"Epoch\" + str(epoch) + '.pth') \t\t\n",
        "\n",
        "\t\t# Validation Stage\n",
        "\t\tfor iter_val, (img_orig, img_haze) in enumerate(val_loader):\n",
        "\n",
        "\t\t\timg_orig = img_orig.cuda()\n",
        "\t\t\timg_haze = img_haze.cuda()\n",
        "\n",
        "\t\t\tclean_image = dehaze_net(img_haze)\n",
        "\n",
        "\t\t\ttorchvision.utils.save_image(torch.cat((img_haze, clean_image, img_orig),0), config.sample_output_folder+str(iter_val+1)+\".jpg\")\n",
        "\n",
        "\t\ttorch.save(dehaze_net.state_dict(), config.snapshots_folder + \"dehazer.pth\") \n",
        "\n",
        "\t\t\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\tparser = argparse.ArgumentParser()\n",
        "\n",
        "\t# Input Parameters\n",
        "\tparser.add_argument('--orig_images_path', type=str, default=\"gdrive/My Drive/PyTorch-Image-Dehazing-master/data/images/\")\n",
        "\tparser.add_argument('--hazy_images_path', type=str, default=\"gdrive/My Drive/PyTorch-Image-Dehazing-master/data/data_1/\")\n",
        "\tparser.add_argument('--lr', type=float, default=0.0001)\n",
        "\tparser.add_argument('--weight_decay', type=float, default=0.0001)\n",
        "\tparser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
        "\tparser.add_argument('--num_epochs', type=int, default=10)\n",
        "\tparser.add_argument('--train_batch_size', type=int, default=64)\n",
        "\tparser.add_argument('--val_batch_size', type=int, default=64)\n",
        "\tparser.add_argument('--num_workers', type=int, default=4)\n",
        "\tparser.add_argument('--display_iter', type=int, default=10)\n",
        "\tparser.add_argument('--snapshot_iter', type=int, default=200)\n",
        "\tparser.add_argument('--snapshots_folder', type=str, default=\"snapshots/\")\n",
        "\tparser.add_argument('--sample_output_folder', type=str, default=\"samples/\")\n",
        "\tparser.add_argument('-f')\n",
        "\n",
        "\tconfig = parser.parse_args()\n",
        "\n",
        "\tif not os.path.exists(config.snapshots_folder):\n",
        "\t\tos.mkdir(config.snapshots_folder)\n",
        "\tif not os.path.exists(config.sample_output_folder):\n",
        "\t\tos.mkdir(config.sample_output_folder)\n",
        "\n",
        "\ttrain(config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}